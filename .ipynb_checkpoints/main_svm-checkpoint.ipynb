{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team Project\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "import scikitplot as skplt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "emotions_list = [\":)\", \":(\", \":p\", \":D\", \"-_-\", \":o\"]\n",
    "import wordcloud\n",
    "stop_words = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text():\n",
    "    for d, ln in zip(messages_data, token_4):\n",
    "        token_1.append(d)\n",
    "        token_2.append(d.count('$'))\n",
    "        x =re.sub('[^0-9 ]+', '', d.lower())\n",
    "        token_3.append(len(x))\n",
    "        if (re.sub(r'[^://@]', '', d.lower())) is not '':\n",
    "            token_6.append(1)\n",
    "        else:\n",
    "            token_6.append(0)\n",
    "        token_7.append(len(x.split()))\n",
    "        for emoji in emotions_list:\n",
    "            if(re.search(re.escape(emoji), d)):\n",
    "                token_8.append(1)\n",
    "            else:\n",
    "                token_8.append(0)\n",
    "    return np.array(\n",
    "        [np.array([token_1[i], token_2[i], token_3[i], token_4[i], token_6[i], token_7[i],token_8[i]], dtype=object) for i in\n",
    "         range(len(messages_data))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_process(mess):\n",
    "    no_punct = re.sub('[^A-Za-z ]+', '', mess.lower())\n",
    "    return np.array([stemmer.stem(word) for word in no_punct.split() if word not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_fit():\n",
    "    SVM = svm.SVC()\n",
    "    SVM.fit(trainset, trainlabel)\n",
    "    predicted_values_svm = SVM.predict(testset)\n",
    "    acurracy_SVM = accuracy_score(testlabel, predicted_values_svm)\n",
    "    print(\"acurracy_SVM \" + str(acurracy_SVM))\n",
    "    confusion_matrix_SVM = confusion_matrix(testlabel,predicted_values_svm,labels=[\"ham\",\"spam\"] )\n",
    "    print(confusion_matrix_SVM)\n",
    "    skplt.metrics.plot_confusion_matrix(testlabel,predicted_values_svm, normalize=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_mapper():\n",
    "    data = preprocessing_text()\n",
    "    labels = ['message','f1','f2','f3','f4','f5','f6']\n",
    "    df = pd.DataFrame.from_records(data,columns=labels)\n",
    "    mapper = DataFrameMapper([\n",
    "    (['f1', 'f2','f3','f4','f5','f6'], None),\n",
    "    ('message',CountVectorizer(analyzer = text_process,ngram_range=(1, 1)))])\n",
    "    X=mapper.fit_transform(df)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_text(lable):\n",
    "    words = ' '.join(list(messages[messages['v1'] == lable]['v2']))\n",
    "    wc = WordCloud(width = 512,height = 512).generate(words)\n",
    "    plt.figure(figsize = (10,8),facecolor = 'k')\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    messages = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "    messages = messages.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])\n",
    "    messages['length'] = messages['v2'].apply(len)\n",
    "    messages_data = messages['v2']\n",
    "    messages_labels = messages['v1']\n",
    "    token_1 = []\n",
    "    token_2 = []\n",
    "    token_3 = []\n",
    "    token_4 = messages['length']\n",
    "    token_6 = []\n",
    "    token_7 = []\n",
    "    token_8 = []\n",
    "    \n",
    "    freq = pd.Series(' '.join(messages_data).split()).value_counts()\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(freq[-9268:].index)\n",
    "    \n",
    "    mapped_data = data_mapper()\n",
    "    trainset, testset, trainlabel, testlabel = train_test_split(mapped_data, messages_labels, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='rbf', C=1)\n",
    "scores = cross_val_score(clf, trainset, trainlabel, cv=5)\n",
    "print(scores)                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(trainset, trainlabel)\n",
    "predicted_values_svm = clf.predict(testset)\n",
    "acurracy_SVM = accuracy_score(testlabel, predicted_values_svm)\n",
    "print(\"acurracy_SVM \" + str(acurracy_SVM))\n",
    "confusion_matrix_SVM = confusion_matrix(testlabel,predicted_values_svm,labels=[\"ham\",\"spam\"])\n",
    "print(confusion_matrix_SVM)\n",
    "skplt.metrics.plot_confusion_matrix(testlabel,predicted_values_svm, normalize=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "scores = cross_val_score(clf, trainset, trainlabel, cv=5)\n",
    "print(scores)                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(trainset,trainlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(testset)\n",
    "print(y_predict)\n",
    "accuracy_XGBClassifier = accuracy_score(testlabel, y_predict)\n",
    "print(\"acurracy_XGBClassifier \" + str(accuracy_XGBClassifier))\n",
    "confusion_matrix_SVM = confusion_matrix(testlabel,y_predict,labels=[\"ham\",\"spam\"] )\n",
    "print(confusion_matrix_SVM)\n",
    "skplt.metrics.plot_confusion_matrix(testlabel,y_predict, normalize=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess = \"Need Some instant cash right now? Get up to 1000$.....TODAY! Reply YES for further info, or NO for UNSUBSCRIBE http://enterprise.com\"\n",
    "no_punct = re.sub('[^A-Za-z ]+', '', mess.lower())\n",
    "print(np.array([stemmer.stem(word) for word in no_punct.split() if word not in stop_words]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
